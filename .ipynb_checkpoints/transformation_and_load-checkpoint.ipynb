{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import io\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25\n",
      "s3.Bucket.objectsCollection(s3.Bucket(name='lems-spot-geodata-dev'), s3.ObjectSummary)\n",
      "Reading data/raw/2022-05-25/denue_1.csv\n",
      "Reading data/raw/2022-05-25/denue_2.csv\n",
      "Reading data/raw/2022-05-25/denue_3.csv\n",
      "Reading data/raw/2022-05-25/denue_4.csv\n",
      "Reading data/raw/2022-05-25/denue_5.csv\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2403696 entries, 0 to 167626\n",
      "Data columns (total 42 columns):\n",
      " #   Column      Dtype  \n",
      "---  ------      -----  \n",
      " 0   id          int64  \n",
      " 1   clee        object \n",
      " 2   nom_estab   object \n",
      " 3   raz_social  object \n",
      " 4   codigo_act  int64  \n",
      " 5   nombre_act  object \n",
      " 6   per_ocu     object \n",
      " 7   tipo_vial   object \n",
      " 8   nom_vial    object \n",
      " 9   tipo_v_e_1  object \n",
      " 10  nom_v_e_1   object \n",
      " 11  tipo_v_e_2  object \n",
      " 12  nom_v_e_2   object \n",
      " 13  tipo_v_e_3  object \n",
      " 14  nom_v_e_3   object \n",
      " 15  numero_ext  float64\n",
      " 16  letra_ext   object \n",
      " 17  edificio    object \n",
      " 18  edificio_e  object \n",
      " 19  numero_int  float64\n",
      " 20  letra_int   object \n",
      " 21  tipo_asent  object \n",
      " 22  nomb_asent  object \n",
      " 23  tipoCenCom  object \n",
      " 24  nom_CenCom  object \n",
      " 25  num_local   object \n",
      " 26  cod_postal  float64\n",
      " 27  cve_ent     int64  \n",
      " 28  entidad     object \n",
      " 29  cve_mun     int64  \n",
      " 30  municipio   object \n",
      " 31  cve_loc     int64  \n",
      " 32  localidad   object \n",
      " 33  ageb        object \n",
      " 34  manzana     int64  \n",
      " 35  telefono    object \n",
      " 36  correoelec  object \n",
      " 37  www         object \n",
      " 38  tipoUniEco  object \n",
      " 39  latitud     float64\n",
      " 40  longitud    float64\n",
      " 41  fecha_alta  object \n",
      "dtypes: float64(5), int64(6), object(31)\n",
      "memory usage: 788.6+ MB\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "bucketname = 'lems-spot-geodata-dev'\n",
    "data_folder = 'data/raw'\n",
    "s3 = boto3.resource('s3')\n",
    "bucket = s3.Bucket(bucketname)\n",
    "today = str(date.today())\n",
    "print(today)\n",
    "directory_name = today\n",
    "prefix_objs = bucket.objects.filter(Prefix=f\"{data_folder}/{directory_name}/denue\")\n",
    "print(prefix_objs)\n",
    "\n",
    "prefix_df = []\n",
    "\n",
    "for obj in prefix_objs:\n",
    "    key = obj.key\n",
    "    body = obj.get()['Body'].read()\n",
    "    print(f'Reading {key}')\n",
    "    temp = pd.read_csv(io.BytesIO(body), encoding='ISO-8859-1', low_memory=False)\n",
    "    prefix_df.append(temp)\n",
    "    \n",
    "df = pd.concat(prefix_df)\n",
    "del prefix_df\n",
    "df.info()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nom_estab</th>\n",
       "      <th>per_ocu</th>\n",
       "      <th>tipo_vial</th>\n",
       "      <th>nom_vial</th>\n",
       "      <th>numero_ext</th>\n",
       "      <th>letra_ext</th>\n",
       "      <th>numero_int</th>\n",
       "      <th>letra_int</th>\n",
       "      <th>tipo_asent</th>\n",
       "      <th>nomb_asent</th>\n",
       "      <th>tipoCenCom</th>\n",
       "      <th>nom_CenCom</th>\n",
       "      <th>num_local</th>\n",
       "      <th>cod_postal</th>\n",
       "      <th>entidad</th>\n",
       "      <th>municipio</th>\n",
       "      <th>localidad</th>\n",
       "      <th>telefono</th>\n",
       "      <th>correoelec</th>\n",
       "      <th>www</th>\n",
       "      <th>latitud</th>\n",
       "      <th>longitud</th>\n",
       "      <th>fecha_alta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45602</td>\n",
       "      <td>AABARROTES LOS PINOS</td>\n",
       "      <td>0 a 5 personas</td>\n",
       "      <td>CALLE</td>\n",
       "      <td>SIERRA DE LA GAVIA</td>\n",
       "      <td>221.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FRACCIONAMIENTO</td>\n",
       "      <td>LAS CUMBRES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20175.0</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>Aguascalientes                                ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.911178</td>\n",
       "      <td>-102.256462</td>\n",
       "      <td>2014-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9340534</td>\n",
       "      <td>ABAROTES ESCOBEDO</td>\n",
       "      <td>0 a 5 personas</td>\n",
       "      <td>CALLE</td>\n",
       "      <td>ING. MIGUEL ANGEL BARBERENA VEGA</td>\n",
       "      <td>518.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FRACCIONAMIENTO</td>\n",
       "      <td>MUNICIPIO LIBRE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>Aguascalientes                                ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.895504</td>\n",
       "      <td>-102.266840</td>\n",
       "      <td>2021-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35543</td>\n",
       "      <td>ABAROTES MARCOS</td>\n",
       "      <td>0 a 5 personas</td>\n",
       "      <td>CALLE</td>\n",
       "      <td>SARGENTO LIBERATO SANTA CRUZ</td>\n",
       "      <td>604.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COLONIA</td>\n",
       "      <td>GREMIAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20030.0</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>Aguascalientes                                ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.893444</td>\n",
       "      <td>-102.291618</td>\n",
       "      <td>2014-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20536</td>\n",
       "      <td>ABAROTES MORALES</td>\n",
       "      <td>0 a 5 personas</td>\n",
       "      <td>CALLE</td>\n",
       "      <td>COSIO SUR</td>\n",
       "      <td>117.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COLONIA</td>\n",
       "      <td>ZONA CENTRO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>Aguascalientes                                ...</td>\n",
       "      <td>4499154508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.881855</td>\n",
       "      <td>-102.286655</td>\n",
       "      <td>2010-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8797198</td>\n",
       "      <td>ABAROTES ROQUE CORDOVA</td>\n",
       "      <td>0 a 5 personas</td>\n",
       "      <td>CALLE</td>\n",
       "      <td>PIÑA</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LOCALIDAD</td>\n",
       "      <td>CANADA GRANDE DE COTORINA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20394.0</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>Aguascalientes</td>\n",
       "      <td>Cañada Grande de Cotorina                     ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.782423</td>\n",
       "      <td>-102.237041</td>\n",
       "      <td>2019-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id               nom_estab         per_ocu tipo_vial  \\\n",
       "0    45602    AABARROTES LOS PINOS  0 a 5 personas     CALLE   \n",
       "1  9340534       ABAROTES ESCOBEDO  0 a 5 personas     CALLE   \n",
       "2    35543         ABAROTES MARCOS  0 a 5 personas     CALLE   \n",
       "3    20536        ABAROTES MORALES  0 a 5 personas     CALLE   \n",
       "4  8797198  ABAROTES ROQUE CORDOVA  0 a 5 personas     CALLE   \n",
       "\n",
       "                           nom_vial  numero_ext letra_ext  numero_int  \\\n",
       "0                SIERRA DE LA GAVIA       221.0       NaN         NaN   \n",
       "1  ING. MIGUEL ANGEL BARBERENA VEGA       518.0       NaN         NaN   \n",
       "2      SARGENTO LIBERATO SANTA CRUZ       604.0       NaN         NaN   \n",
       "3                         COSIO SUR       117.0       NaN         0.0   \n",
       "4                              PIÑA       106.0         1         NaN   \n",
       "\n",
       "  letra_int       tipo_asent                 nomb_asent tipoCenCom nom_CenCom  \\\n",
       "0       NaN  FRACCIONAMIENTO                LAS CUMBRES        NaN        NaN   \n",
       "1       NaN  FRACCIONAMIENTO            MUNICIPIO LIBRE        NaN        NaN   \n",
       "2       NaN          COLONIA                    GREMIAL        NaN        NaN   \n",
       "3       NaN          COLONIA                ZONA CENTRO        NaN        NaN   \n",
       "4       NaN        LOCALIDAD  CANADA GRANDE DE COTORINA        NaN        NaN   \n",
       "\n",
       "  num_local  cod_postal         entidad       municipio  \\\n",
       "0       NaN     20175.0  Aguascalientes  Aguascalientes   \n",
       "1       NaN         NaN  Aguascalientes  Aguascalientes   \n",
       "2       NaN     20030.0  Aguascalientes  Aguascalientes   \n",
       "3       NaN     20000.0  Aguascalientes  Aguascalientes   \n",
       "4       NaN     20394.0  Aguascalientes  Aguascalientes   \n",
       "\n",
       "                                           localidad    telefono correoelec  \\\n",
       "0  Aguascalientes                                ...         NaN        NaN   \n",
       "1  Aguascalientes                                ...         NaN        NaN   \n",
       "2  Aguascalientes                                ...         NaN        NaN   \n",
       "3  Aguascalientes                                ...  4499154508        NaN   \n",
       "4  Cañada Grande de Cotorina                     ...         NaN        NaN   \n",
       "\n",
       "   www    latitud    longitud fecha_alta  \n",
       "0  NaN  21.911178 -102.256462    2014-12  \n",
       "1  NaN  21.895504 -102.266840    2021-05  \n",
       "2  NaN  21.893444 -102.291618    2014-12  \n",
       "3  NaN  21.881855 -102.286655    2010-07  \n",
       "4  NaN  21.782423 -102.237041    2019-11  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['clee', 'raz_social', 'codigo_act', 'nombre_act', 'tipo_v_e_1', 'nom_v_e_1', 'tipo_v_e_2', 'nom_v_e_2', 'tipo_v_e_3', 'nom_v_e_3', 'edificio', 'edificio_e', 'ageb', 'manzana', 'tipoUniEco', 'cve_mun', 'cve_ent', 'cve_loc'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "bucketname = 'lems-spot-geodata-dev'\n",
    "data_folder = 'data/output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-25\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'CP4M06YSP60E16Z0',\n",
       "  'HostId': 'nQYVKwod5NfR7/EaaVHB7SKLoM+IcS3qQ4RCvljTsRmjotS13dmCCpIgls8OMVLTIdds41nDb3g=',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amz-id-2': 'nQYVKwod5NfR7/EaaVHB7SKLoM+IcS3qQ4RCvljTsRmjotS13dmCCpIgls8OMVLTIdds41nDb3g=',\n",
       "   'x-amz-request-id': 'CP4M06YSP60E16Z0',\n",
       "   'date': 'Wed, 25 May 2022 01:31:15 GMT',\n",
       "   'etag': '\"d41d8cd98f00b204e9800998ecf8427e\"',\n",
       "   'server': 'AmazonS3',\n",
       "   'content-length': '0'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ETag': '\"d41d8cd98f00b204e9800998ecf8427e\"'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "today = str(date.today())\n",
    "print(today)\n",
    "directory_name = today\n",
    "s3.put_object(Bucket=bucketname, Key=(f'{data_folder}/'+directory_name+'/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"s3://{bucketname}/{data_folder}/{directory_name}/denue.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Redshift client\n",
    "redshift = boto3.client(\n",
    "    \"redshift\",\n",
    "    region_name = \"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Create IAM client for region us-east-1 feeding AWS credentials extracted from the config.json file\n",
    "iam = boto3.client(\n",
    "    \"iam\",\n",
    "    region_name = \"us-east-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role named 'DataEngineer' already exists\n",
      "An error occurred (DeleteConflict) when calling the DeleteRole operation: Cannot delete entity, must delete policies first.\n",
      "An error occurred (EntityAlreadyExists) when calling the CreateRole operation: Role with name DataEngineer already exists.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import json\n",
    "\n",
    "role_name = \"DataEngineer\"\n",
    "\n",
    "# Create IAM client for region us-east-1 feeding AWS credentials extracted from the config.json file\n",
    "iam = boto3.client(\n",
    "    \"iam\",\n",
    "    region_name = \"us-east-1\")\n",
    "\n",
    "# Try to delete the existing role with the same name, if exists\n",
    "try:\n",
    "    role = iam.get_role(\n",
    "        RoleName = role_name\n",
    "    )\n",
    "    print(\"Role named '{}' already exists\".format(role_name))\n",
    "\n",
    "    # Extract all the attached policies to the existing role\n",
    "    attached_policies = iam.list_attached_role_policies(\n",
    "        RoleName = role_name\n",
    "    )[\n",
    "        \"AttachedPolicies\"\n",
    "    ]\n",
    "\n",
    "\n",
    "    # Iterate over all attached policies\n",
    "    for attached_policy in attached_policies:\n",
    "\n",
    "        # Extract attached policy ARN\n",
    "        attached_policy_arn = attached_policy[\n",
    "            \"PolicyArn\"\n",
    "        ]\n",
    "\n",
    "        # Detach policy from role\n",
    "        iam.detach_role_policy(\n",
    "            RoleName = role_name,\n",
    "            PolicyArn = attached_policy_arn\n",
    "        )\n",
    "\n",
    "    # Delete role\n",
    "    try:\n",
    "        delete_role = iam.delete_role(\n",
    "            RoleName = role_name\n",
    "        )\n",
    "        print(\"Role named '{}' has been deleted\".format(role_name))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        \n",
    "except Exception as e:\n",
    "    print(str(e))\n",
    "\n",
    "# Create IAM role\n",
    "try:\n",
    "    role = iam.create_role(\n",
    "        RoleName = role_name,\n",
    "        Description = \"Allows Redshift cluster to call AWS services on behalf of the user\",\n",
    "        AssumeRolePolicyDocument = json.dumps(\n",
    "            {\n",
    "                \"Statement\": [\n",
    "                    {\n",
    "                        \"Action\": \"sts:AssumeRole\",\n",
    "                        \"Effect\": \"Allow\",\n",
    "                        \"Principal\": {\n",
    "                            \"Service\": \"redshift.amazonaws.com\"\n",
    "                        }\n",
    "                     }\n",
    "                ],\n",
    "                \"Version\": \"2012-10-17\"\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    print(\"Role named '{}' has been created\".format(role_name))\n",
    "\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role DataEngineer's ARN is: arn:aws:iam::157310664496:role/DataEngineer\n"
     ]
    }
   ],
   "source": [
    "# Extract role ARN\n",
    "role_arn = iam.get_role(\n",
    "    RoleName = role_name\n",
    ")[\"Role\"][\"Arn\"]\n",
    "print(\"Role {}'s ARN is: {}\".format(role_name, role_arn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy named 'policy_new' already exists\n",
      "Policy with ARN 'arn:aws:iam::157310664496:policy/policy_new' deleted\n",
      "Policy named 'policy_new' created\n",
      "Policy named 'policy_new' has ARN 'arn:aws:iam::157310664496:policy/policy_new'\n"
     ]
    }
   ],
   "source": [
    "# Check if policy with the wanted name already exists\n",
    "policy_name = \"policy_new\"\n",
    "try:\n",
    "    policies = iam.list_policies()[\"Policies\"]\n",
    "    policy_exists = False\n",
    "    for policy in policies:\n",
    "        if policy[\"PolicyName\"] == policy_name:\n",
    "            existing_policy_arn = policy[\"Arn\"]\n",
    "            policy_exists = True\n",
    "            break          \n",
    "except:\n",
    "    None\n",
    "\n",
    "# If a policy with the same name already exists, delete it\n",
    "if policy_exists:\n",
    "    print(\"Policy named '{}' already exists\".format(policy_name))\n",
    "    \n",
    "    # Extract all roles\n",
    "    roles = iam.list_roles()[\"Roles\"]\n",
    "    \n",
    "    # Iterate over all the roles\n",
    "    for role in roles:\n",
    "        \n",
    "        # Extract role name\n",
    "        existing_role_name = role[\"RoleName\"]\n",
    "        \n",
    "        # Extract all the attached policy to the role\n",
    "        attached_policies = iam.list_attached_role_policies(\n",
    "            RoleName = existing_role_name\n",
    "        )[\"AttachedPolicies\"]\n",
    "        \n",
    "        # Iterate over all the attached policies\n",
    "        for attached_policy in attached_policies:\n",
    "\n",
    "            # Extract attached policy ARN\n",
    "            attached_policy_arn = attached_policy[\"PolicyArn\"]\n",
    "\n",
    "            # Checking if the policy correspond to the wanted one\n",
    "            if attached_policy_arn == existing_policy_arn:\n",
    "                \n",
    "                # Detach policy from role\n",
    "                iam.detach_role_policy(\n",
    "                    RoleName = existing_role_name,\n",
    "                    PolicyArn = attached_policy_arn\n",
    "                )\n",
    "                \n",
    "                print(\"Policy with ARN '{}' detached from role '{}'\".format(policy_arn, existing_role_name))\n",
    "    \n",
    "    # Extract all the policy versions\n",
    "    policy_versions = iam.list_policy_versions(\n",
    "        PolicyArn = existing_policy_arn\n",
    "    )[\"Versions\"]\n",
    "    \n",
    "    # Iterate over all the policy versions\n",
    "    for policy_version in policy_versions:\n",
    "        \n",
    "        # Skip the version if it is a default version\n",
    "        if policy_version[\"IsDefaultVersion\"]:\n",
    "            continue\n",
    "          \n",
    "        # Extract policy ID\n",
    "        version_id = policy_version[\"VersionId\"]\n",
    "        \n",
    "        # Delete policy version\n",
    "        iam.delete_policy_version(\n",
    "            PolicyArn = existing_policy_arn,\n",
    "            VersionId = version_id\n",
    "        )\n",
    "        print(\"Policy with ARN '{}', version_ID '{}' deleted\".format(existing_policy_arn, version_id))\n",
    "    \n",
    "    # Delete default version of the policy\n",
    "    iam.delete_policy(\n",
    "        PolicyArn = existing_policy_arn\n",
    "    )\n",
    "    print(\"Policy with ARN '{}' deleted\".format(existing_policy_arn))\n",
    "    \n",
    "else:\n",
    "    print(\"Policy named '{}' does not exists\".format(policy_name))\n",
    " \n",
    "# Create policy \n",
    "try:\n",
    "    policy = iam.create_policy(\n",
    "        PolicyName = policy_name,\n",
    "        Description = \"Allow to list and access content of the target bucket 'data-to-migrate'\",\n",
    "        PolicyDocument = json.dumps(\n",
    "            {\n",
    "                \"Version\": \"2012-10-17\",\n",
    "                \"Statement\": [\n",
    "                    {\n",
    "                        \"Effect\": \"Allow\",\n",
    "                        \"Action\": [\n",
    "                            \"s3:ListBucket\"\n",
    "                        ],\n",
    "                        \"Resource\": [\n",
    "                            \"arn:aws:s3:::data-to-migrate\"\n",
    "                        ]\n",
    "                    },\n",
    "                    {\n",
    "                        \"Effect\": \"Allow\",\n",
    "                        \"Action\": [\n",
    "                            \"s3:PutObject\",\n",
    "                            \"s3:GetObject\",\n",
    "                            \"s3:DeleteObject\"\n",
    "                        ],\n",
    "                        \"Resource\": [\n",
    "                            \"arn:aws:s3:::data-to-migrate/*\"\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    print(\"Policy named '{}' created\".format(policy_name))\n",
    "    policy_arn = policy[\"Policy\"][\"Arn\"]\n",
    "    print(\"Policy named '{}' has ARN '{}'\".format(policy_name, policy_arn))\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy named policy_new attached to role DataEngineer\n"
     ]
    }
   ],
   "source": [
    "# Attach policy to IAM role\n",
    "try:\n",
    "    attachment = iam.attach_role_policy(\n",
    "        RoleName = role_name,\n",
    "        PolicyArn = policy_arn\n",
    "    )\n",
    "    print(\"Policy named {} attached to role {}\".format(policy_name, role_name))\n",
    "except Exception as e:\n",
    "    print(str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_identifier = \"redshift-cluster-geodata\"\n",
    "cluster_type       = \"single-node\" \n",
    "node_type          = \"dc2.large\"\n",
    "username           = \"awsuser\"\n",
    "password           = \"Passw0rd\"\n",
    "database_name      = \"dev-geodata\"\n",
    "port               = 5439\n",
    "redshift_endpoint  = \"redshift-cluster-geodata.ch3hvj0f1a3k.us-east-1.redshift.amazonaws.com\"\n",
    "cluster_endpoint   = \"redshift-cluster-geodata.ch3hvj0f1a3k.us-east-1.redshift.amazonaws.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete Redshift cluster with the same name if it exists\n",
    "   \n",
    "try:\n",
    "    # Delete Cluster\n",
    "    redshift.delete_cluster(\n",
    "        ClusterIdentifier = cluster_identifier,\n",
    "        SkipFinalClusterSnapshot = True,\n",
    "    )\n",
    "\n",
    "    print(\"A cluster named '{}' already exists\".format(cluster_identifier))\n",
    "    print(\"Deleting existing cluster named '{}'...\".format(cluster_identifier))\n",
    "\n",
    "\n",
    "    # Wait for the cluster status change to deleted\n",
    "    delete_waiter = redshift.get_waiter(\"cluster_deleted\")\n",
    "    delete_waiter.wait(\n",
    "        ClusterIdentifier = cluster_identifier,\n",
    "        WaiterConfig = {\n",
    "            \"Delay\": 30,\n",
    "            \"MaxAttempts\": 20\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(\"Existing cluster named '{}' deleted\".format(cluster_identifier))\n",
    "\n",
    "except:\n",
    "    print(\"A cluster named '{}' does not exist\".format(cluster_identifier))  \n",
    "\n",
    "\n",
    "# Create Redshift cluster\n",
    "try:\n",
    "    cluster = redshift.create_cluster(\n",
    "        DBName = database_name, # (OPT) name of the first database to create when the cluster is created\n",
    "        ClusterIdentifier = cluster_identifier, # (REQ) name of the cluster\n",
    "        ClusterType = cluster_type, # (OPT) singlenode vs multinode\n",
    "        NodeType = node_type, # (REQ) type of node\n",
    "        MasterUsername = username, # (REQ) username\n",
    "        MasterUserPassword = password, # (REQ) password\n",
    "        Port = port, # port number on which the cluster accepts inbound connections\n",
    "        IamRoles = [role_arn] # list of role Arns defining how Redshift can access other AWS services\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "print(\"Creating new cluster named '{}'...\".format(cluster_identifier))\n",
    "\n",
    "# Wait for the new cluster status change to available\n",
    "create_waiter = redshift.get_waiter(\"cluster_available\")\n",
    "create_waiter.wait(\n",
    "        ClusterIdentifier = cluster_identifier,\n",
    "        WaiterConfig = {\n",
    "            \"Delay\": 30,\n",
    "            \"MaxAttempts\": 20\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"New cluster named '{}' created and available\".format(cluster_identifier))\n",
    "\n",
    "# Extract cluster info\n",
    "clusters = redshift.describe_clusters(\n",
    "        ClusterIdentifier = cluster_identifier\n",
    "    )[\"Clusters\"]\n",
    "\n",
    "for cluster in clusters:\n",
    "    if cluster[\"ClusterIdentifier\"] ==  cluster_identifier:\n",
    "        break\n",
    "\n",
    "cluster_endpoint = cluster[\"Endpoint\"][\"Address\"]\n",
    "vpc_security_group_id = cluster[\"VpcSecurityGroups\"][0][\"VpcSecurityGroupsId\"]\n",
    "\n",
    "print(\"Cluster '{}' endpoint is '{}'\").format(cluster_identifier, cluster_endpoint)\n",
    "print(\"Cluster '{}''s VPC security group ID is '{}'\").format(cluster_identifier, vpc_security_group_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster '{}' endpoint is '{}'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'format'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-621d15ea1dc5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcluster_endpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcluster\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Endpoint\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Address\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Cluster '{}' endpoint is '{}'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcluster_identifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_endpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'format'"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a VPC security group rule to authorize ingress to the cluster's VPC Security Group\n",
    "vpc_security_group_id = \"sg-0d9ad589427fc57d3\"\n",
    "try:\n",
    "    # Define EC2 resource\n",
    "    ec2 = boto3.resource(\n",
    "        \"ec2\",\n",
    "        region_name = \"us-east-1\"    )\n",
    "\n",
    "    # Extract security group for the VPC\n",
    "    vpc_sg = ec2.SecurityGroup(id = vpc_security_group_id)\n",
    "    \n",
    "    # Authorize connection to the VPC\n",
    "    vpc_sg.authorize_ingress(\n",
    "        GroupName = vpc_sg.group_name,\n",
    "        CidrIp = \"0.0.0.0/0\",\n",
    "        IpProtocol = \"TCP\",\n",
    "        FromPort = 5439,\n",
    "        ToPort = 5439\n",
    "    )\n",
    "    print(\"Ingress to the VPC authorized\")\n",
    "    \n",
    "except Exception as e:\n",
    "    \n",
    "    # Check if the error is a duplication error\n",
    "    if \"InvalidPermission.Duplicate\" in str(e):\n",
    "        print(\"Rule requested already exists\")\n",
    "    else:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipython-sql in /opt/conda/lib/python3.7/site-packages (0.4.0)\n",
      "Requirement already satisfied: ipython-genutils>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: ipython>=1.0 in /opt/conda/lib/python3.7/site-packages (from ipython-sql) (7.32.0)\n",
      "Requirement already satisfied: sqlparse in /opt/conda/lib/python3.7/site-packages (from ipython-sql) (0.4.2)\n",
      "Requirement already satisfied: prettytable<1 in /opt/conda/lib/python3.7/site-packages (from ipython-sql) (0.7.2)\n",
      "Requirement already satisfied: sqlalchemy>=0.6.7 in /opt/conda/lib/python3.7/site-packages (from ipython-sql) (1.4.32)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from ipython-sql) (1.16.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (61.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (4.8.0)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (0.1.3)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (5.1.1)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (3.0.20)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (0.18.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (0.7.5)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (5.1.1)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.7/site-packages (from ipython>=1.0->ipython-sql) (2.11.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from jedi>=0.16->ipython>=1.0->ipython-sql) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.7/site-packages (from pexpect>4.3->ipython>=1.0->ipython-sql) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=1.0->ipython-sql) (0.2.5)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.7/site-packages (from sqlalchemy>=0.6.7->ipython-sql) (1.1.1)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from sqlalchemy>=0.6.7->ipython-sql) (4.11.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy>=0.6.7->ipython-sql) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->sqlalchemy>=0.6.7->ipython-sql) (4.2.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.1.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython-sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cluster_endpoint' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-522245374198>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcluster_endpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cluster_endpoint' is not defined"
     ]
    }
   ],
   "source": [
    "cluster_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sql extension is already loaded. To reload it, use:\n",
      "  %reload_ext sql\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "# Define connection string\n",
    "%load_ext sql\n",
    "conn_string = \"postgresql://{}:{}@{}:{}/{}\".format(\n",
    "    username,\n",
    "    password,\n",
    "    cluster_endpoint,\n",
    "    port,\n",
    "    database_name\n",
    ")\n",
    "\n",
    "# Test connection\n",
    "%sql $conn_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_sql(\n",
    "        sql_query,\n",
    "        conn_string,\n",
    "        print_results = False\n",
    "    ):\n",
    "    \"\"\"Execute a SQL query on the database associated with\n",
    "       a connection string\n",
    "    \n",
    "    Parameters:\n",
    "    - sql_query : str\n",
    "        SQL query to execute\n",
    "    - conn_string : str\n",
    "        connection string of the format 'postgresql://MasterUsername:MasterUserPassword@ClusterEndpoint:DatabasePort,DatabaseName'\n",
    "    - print_results : bool\n",
    "        select if to print query results or not\n",
    "    \"\"\"\n",
    "    \n",
    "    # Connect to the database\n",
    "    conn = psycopg2.connect(conn_string)\n",
    "    \n",
    "    # Define cursor\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Execute query\n",
    "    cur.execute(sql_query)\n",
    "    conn.commit()\n",
    "    if print_results:\n",
    "        print(cur.fetchall())\n",
    "\n",
    "    # Close cursor\n",
    "    cur.close()\n",
    "    \n",
    "    # Close connection\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define S3 client\n",
    "import boto3\n",
    "s3 = boto3.client(\n",
    "    \"s3\")\n",
    "\n",
    "# Get object containing file to be staged\n",
    "obj = s3.get_object(\n",
    "    Bucket = bucketname,\n",
    "    Key = f\"{data_folder}/{directory_name}/denue.csv\"\n",
    ")\n",
    "\n",
    "import io\n",
    "import pandas as pd\n",
    "\n",
    "# Print colummns info for the dataset\n",
    "pd.read_csv(io.BytesIO(obj[\"Body\"].read()),  low_memory=False).info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'redshift-cluster-geodata.ch3hvj0f1a3k.us-east-1.redshift.amazonaws.com'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "redshift = boto3.client(\n",
    "    \"redshift\",\n",
    "    region_name = \"us-east-1\")\n",
    "clusters = redshift.describe_clusters(\n",
    "        ClusterIdentifier = cluster_identifier\n",
    "    )[\"Clusters\"]\n",
    "\n",
    "for cluster in clusters:\n",
    "    if cluster[\"ClusterIdentifier\"] ==  cluster_identifier:\n",
    "        break\n",
    "\n",
    "cluster_endpoint = cluster[\"Endpoint\"][\"Address\"]\n",
    "cluster_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role DataEngineer's ARN is: arn:aws:iam::157310664496:role/DataEngineer\n"
     ]
    }
   ],
   "source": [
    "iam = boto3.client(\n",
    "    \"iam\",\n",
    "    region_name = \"us-east-1\")\n",
    "role_arn = iam.get_role(\n",
    "    RoleName = role_name\n",
    ")[\"Role\"][\"Arn\"]\n",
    "print(\"Role {}'s ARN is: {}\".format(role_name, role_arn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"UserId\": \"AROASJIDSH4YPESDEJIVI:SageMaker\",\n",
      "    \"Account\": \"157310664496\",\n",
      "    \"Arn\": \"arn:aws:sts::157310664496:assumed-role/AmazonSageMaker-ExecutionRole-20211013T113110/SageMaker\"\n",
      "}\n",
      "arn:aws:iam::157310664496:role/DataEngineer\n",
      "s3://lems-spot-geodata-dev/data/output/2022-05-25/denue.csv\n"
     ]
    }
   ],
   "source": [
    "!aws sts get-caller-identity\n",
    "print(role_arn)\n",
    "data_folder = \"data/output\"\n",
    "# Delete existing table named \"iris\"\n",
    "sql_query = \"\"\"DROP TABLE IF EXISTS denue CASCADE\"\"\"\n",
    "execute_sql(sql_query, conn_string)\n",
    "\n",
    "# Create a new table named \"iris\"\n",
    "sql_query = \"\"\"CREATE TABLE IF NOT EXISTS denue\n",
    "               (\n",
    "               id NUMERIC,\n",
    "               nom_estab VARCHAR,\n",
    "               per_ocu VARCHAR,\n",
    "               tipo_vial VARCHAR,\n",
    "               nom_vial VARCHAR,\n",
    "               numero_ext NUMERIC,\n",
    "               letra_ext VARCHAR,\n",
    "               numero_int NUMERIC,\n",
    "               letra_int VARCHAR,\n",
    "               tipo_asent VARCHAR,\n",
    "               nomb_asent VARCHAR,\n",
    "               tipoCenCom VARCHAR,\n",
    "               nom_CenCom VARCHAR,\n",
    "               num_local VARCHAR,\n",
    "               cod_postal FLOAT4,\n",
    "               entidad VARCHAR,\n",
    "               municipio VARCHAR,\n",
    "               localidad VARCHAR,\n",
    "               telefono VARCHAR,\n",
    "               correoelec VARCHAR,\n",
    "               www VARCHAR,\n",
    "               latitud FLOAT4,\n",
    "               longitud FLOAT4,\n",
    "               fecha_alta VARCHAR\n",
    "               )\n",
    "            \"\"\"\n",
    "execute_sql(sql_query, conn_string)\n",
    "\n",
    "# Define S3 source file path\n",
    "file_path = f\"s3://{bucketname}/{data_folder}/{directory_name}/denue.csv\"\n",
    "print(file_path)\n",
    "\n",
    "# Copy data\n",
    "sql_query = \"\"\"\n",
    "    COPY denue\n",
    "    FROM '{}'\n",
    "    IAM_ROLE '{}' \n",
    "    emptyasnull\n",
    "    blanksasnull    \n",
    "    REMOVEQUOTES\n",
    "    delimiter as ','\n",
    "    IGNOREHEADER 1\n",
    "    maxerror as 250\n",
    "    ;\n",
    "\"\"\".format(file_path, role_arn)\n",
    "execute_sql(sql_query, conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://lems-spot-geodata-dev/data/targets.csv\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"data\"\n",
    "\n",
    "sql_query = \"\"\"DROP TABLE IF EXISTS targets CASCADE\"\"\"\n",
    "execute_sql(sql_query, conn_string)\n",
    "\n",
    "sql_query = \"\"\"CREATE TABLE IF NOT EXISTS targets\n",
    "               (\n",
    "               spot VARCHAR,\n",
    "               direccion VARCHAR,\n",
    "               latitud FLOAT4,\n",
    "               longitud FLOAT4\n",
    "            )\n",
    "            \"\"\"\n",
    "execute_sql(sql_query, conn_string)\n",
    "\n",
    "# Define S3 source file path\n",
    "file_path = f\"s3://{bucketname}/{data_folder}/targets.csv\"\n",
    "print(file_path)\n",
    "\n",
    "# Copy data\n",
    "sql_query = \"\"\"\n",
    "    COPY targets\n",
    "    FROM '{}'\n",
    "    IAM_ROLE '{}' \n",
    "    emptyasnull\n",
    "    blanksasnull    \n",
    "    REMOVEQUOTES\n",
    "    delimiter as ','\n",
    "    IGNOREHEADER 1\n",
    "    maxerror as 250\n",
    "    ;\n",
    "\"\"\".format(file_path, role_arn)\n",
    "execute_sql(sql_query, conn_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "sql_query = \"\"\"DROP VIEW IF EXISTS v_targets CASCADE\"\"\"\n",
    "execute_sql(sql_query, conn_string)\n",
    "\n",
    "sql_query = \"\"\"CREATE VIEW v_targets AS\n",
    "SELECT spot, direccion, latitud as latitud_target, longitud as longitud_target, RADIANS(latitud) as lat_radians, RADIANS(longitud) as long_radians\n",
    "FROM targets\n",
    "            \"\"\"\n",
    "execute_sql(sql_query, conn_string)\n",
    "\n",
    "sql_query = \"\"\"DROP VIEW IF EXISTS v_denue_pizza CASCADE\"\"\"\n",
    "execute_sql(sql_query, conn_string)\n",
    "\n",
    "sql_query = \"\"\"CREATE VIEW v_denue_pizza AS\n",
    "SELECT id, nom_estab, per_ocu, nom_vial, numero_ext, cod_postal, municipio, localidad, latitud as latitud_source, longitud as longitud_source, RADIANS(latitud) as lat_radians_source, RADIANS(longitud) as long_radians_source, fecha_alta FROM denue\n",
    "WHERE nom_estab LIKE '%PIZZ%'\n",
    "            \"\"\"\n",
    "execute_sql(sql_query, conn_string)\n",
    "\n",
    "sql_query = \"\"\"DROP VIEW IF EXISTS v_pizza_dlonlat CASCADE\"\"\"\n",
    "execute_sql(sql_query, conn_string)\n",
    "\n",
    "sql_query = \"\"\"CREATE VIEW v_pizza_dlonlat AS\n",
    "SELECT T.*, T.long_radians-S.long_radians_source as dlon, T.lat_radians-S.lat_radians_source as dlat, S.* FROM v_denue_pizza S, v_targets T\n",
    "            \"\"\"\n",
    "execute_sql(sql_query, conn_string)\n",
    "\n",
    "sql_query = \"\"\"DROP VIEW IF EXISTS v_pizza_distances CASCADE\"\"\"\n",
    "execute_sql(sql_query, conn_string)\n",
    "\n",
    "sql_query = \"\"\"CREATE VIEW v_pizza_distances AS\n",
    "SELECT *, pow(sin(dlat / 2),2) + cos(lat_radians_source) * cos(lat_radians) * pow(sin(dlon / 2),2) as a, 2 * asin(sqrt(a)) as c, 6371*c as distance FROM v_pizza_dlonlat\n",
    "            \"\"\"\n",
    "execute_sql(sql_query, conn_string)\n",
    "\n",
    "sql_query = \"\"\"DROP VIEW IF EXISTS v_pizza_result\"\"\"\n",
    "execute_sql(sql_query, conn_string)\n",
    "\n",
    "sql_query = \"\"\"CREATE VIEW v_pizza_result AS\n",
    "select spot, direccion, latitud_target, longitud_target, nom_estab, per_ocu, nom_vial, numero_ext, latitud_source, longitud_source, distance, to_date(fecha_alta, 'yyyy-mm') as fecha from v_pizza_distances\n",
    "where distance < 4 and extract(year from fecha) >= extract(year from CURRENT_DATE)-3\n",
    "            \"\"\"\n",
    "execute_sql(sql_query, conn_string)\n",
    "\n",
    "print('Done')"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
